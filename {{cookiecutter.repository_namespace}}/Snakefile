## =============================================================================
## WORKFLOW PROJECT: {{cookiecutter.repository_namespace}}
## INIT DATE: {{cookiecutter.date}}
import pandas as pd
import glob, os, datetime, sys, csv, logging
from os.path import join, abspath, isfile
from snakemake.utils import validate, min_version

## ============================================================================
## require minimum snakemake version ##
min_version("{{cookiecutter.min_snakemake_version}}")

## ============================================================================
## SETUP
## ============================================================================

## SET SOME DEFAULT PATH
DIR_SCRIPTS = abspath("scripts")
DIR_WRAPPER = abspath("wrapper")
DIR_REPORT  = abspath("report")
DIR_ENVS    = abspath("envs")
DIR_RULES   = abspath("rules")
DIR_SCHEMAS = abspath("schemas")

## LOAD VARIABLES FROM CONFIGFILE
## submit on command-line via --configfile
if config=={}:
    sys.stderr.write('Please submit config-file with "--configfile <file>". Exit.\n')
    sys.exit(1)

sys.stderr.write("********** Submitted config: **********\n")
for k,v in config.items():
    sys.stderr.write("{}: {}\n".format(k,v))
sys.stderr.write("***************************************\n")

## Validate configfile with yaml-schema
validate(config, schema=join(DIR_SCHEMAS, "config.schema.yaml"))

## define global Singularity image for reproducibility
## USE: "--use-singularity --use-conda" to run all jobs in container
singularity: config["singularity"] 

## Setup result dirs
DIR_BASE       = abspath(config["resultdir"])
DIR_LOGS       = join(DIR_BASE, "logs")
DIR_BENCHMARKS = join(DIR_BASE, "benchmarks")
DIR_RES        = join(DIR_BASE, "results")

## Workflow specific setup from config ========================================

example_extra = config["extra"]["example"]

## ============================================================================
## Reading samples from sheet
samples = pd.read_csv(config["samples"], sep=",").set_index("sample", drop=False)
# validate samplesheet
validate(samples, schema=join(DIR_SCHEMAS, "samples.schema.yaml"))

## Testing if samples exist
## reading samplename from samplesheet
sys.stderr.write('Reading samples from samplesheet: "{}" ...\n'.format(config["samples"]))
for fname in samples["fq1"]:
    if not isfile(fname):
        logger.error("File '{}' from samplesheet can not be found. Make sure the file exists. Exit.\n".format(fname))
        sys.exit(1)
    
for fname in samples["fq2"]:
    if pd.isnull(fname):
        continue
    if not isfile(fname):
        logger.error("File '{}' from samplesheet can not be found. Make sure the file exists. Exit.\n".format(fname))
        sys.exit(1)

sys.stderr.write('{} samples to process\n'.format(len(samples["sample"])))

## ============================================================================
## FUNCTIONS
## ============================================================================
def get_fastq(wildcards):
    # does not return fq2 if it is not present
    return samples.loc[(wildcards.sample), ["fq1", "fq2"]].dropna()

## ============================================================================
## SETUP FINAL TARGETS
## ============================================================================

# final files from samples
TARGETS = expand(join(DIR_RES, "final/{sample}.txt"), sample=samples["sample"])
#print(TARGETS)

## ============================================================================
## RULES
## ============================================================================

## Pseudo-rule to state the final targets, so that the whole runs
rule all:
    input:
        TARGETS


rule example:
    input:
        get_fastq
    output:
        touch(join(DIR_RES, "final/{sample}.txt"))


# Include rules from other files
# include: join(DIR_RULES, "example.smk")  

# run with 
# snakemake --configfile config.yaml clean
rule clean:
    shell:
        "rm -rf {DIR_BASE}/*"
