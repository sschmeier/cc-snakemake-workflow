## =============================================================================
## WORKFLOW PROJECT: {{cookiecutter.package_name}}
## INIT DATE: {{cookiecutter.date}}
import pandas as pd
import glob, os, os.path, datetime, sys, csv
from os.path import join, abspath
from snakemake.utils import validate, min_version

## =============================================================================
## set minimum snakemake version #####
min_version("5.5.0")

## =============================================================================
## SETUP
## =============================================================================

## SET SOME DEFAULT PATH
DIR_SCRIPTS = abspath("scripts")
DIR_WRAPPER = abspath("wrapper")
DIR_REPORT  = abspath("report")
DIR_ENVS    = abspath("envs")
DIR_RULES   = abspath("rules")
DIR_SCHEMAS = abspath("schemas")

## LOAD VARIABLES FROM CONFIGFILE
## submit on command-line via --configfile
if config=={}:
    print('Please submit config-file with "--configfile <file>". Exit.')
    sys.exit(1)

## Validate configfile with yaml-schema
validate(config, schema=join(DIR_SCHEMAS, "config.schema.yaml"))

## define global Singularity image for reproducibility
## USE: "--use-singularity --use-conda" to run all jobs in container
singularity: config["singularity"] 

## Setup result dirs
DIR_BASE       = abspath(config["resultdir"])
DIR_LOGS       = join(DIR_BASE, "logs")
DIR_BENCHMARKS = join(DIR_BASE, "benchmarks")
DIR_RES        = join(DIR_BASE, "results")

## Workflow specific setup
# GENOME
GENOME        = abspath(config["ref"]["index"])
ANNOTATION    = abspath(config["ref"]["annotation"])

## =============================================================================
## SAMPLES
samples = pd.read_csv(config["samples"], sep=",").set_index("sample", drop=False)
validate(samples, schema=join(DIR_SCHEMAS, "samples.schema.yaml"))

## reading samplename from samplesheet
sys.stderr.write('Reading samples from samplesheet: "{}" ...\n'.format(config["samples"]))

## test if sample in dir
for fname in samples["fq1"]:
    if not os.path.isfile(fname):
        sys.stderr.write("File '{}' from samplesheet can not be found. Make sure the file exists. Exit\n".format(fname))
        sys.exit()
    
for fname in samples["fq2"]:
    if pd.isnull(fname):
        continue
    if not os.path.isfile(fname):
        sys.stderr.write("File '{}' from samplesheet can not be found. Make sure the file exists. Exit\n".format(fname))
        sys.exit()

NUM_SAMPLES = len(samples["sample"])
sys.stderr.write('{} samples to process\n'.format(NUM_SAMPLES))


## =============================================================================
## SETUP FINAL TARGETS
## =============================================================================

TARGETS = expand(join(DIR_RES, "03_varcalls/{sample}.vcf"), sample=samples["sample"])
#print(TARGETS)


## =============================================================================
## FUNCTIONS
## =============================================================================
def get_fastq(wildcards):
    # does not return fq2 if it is not present
    return samples.loc[(wildcards.sample), ["fq1", "fq2"]].dropna()


## =============================================================================
## RULES
## =============================================================================

## Pseudo-rule to state the final targets, so that the whole runs
rule all:
    input:
        TARGETS


## 1. MAPPING
rule bwa_mem:
    input:
        get_fastq
    output:
        temp(join(DIR_RES, "01_aligned/{sample}.bam"))
    log:
        join(DIR_LOGS, "bwa_mem/{sample}.log")
    benchmark:
        join(DIR_BENCHMARKS, "bwa_mem/{sample}.txt")
    threads: 4
    conda:
        join(DIR_ENVS, "bwa-samtools.yaml")
    params:
        index=GENOME,
        extra=config["extra"]["bwa_mem"],
    ## When using a wrapper, specify dir with wrapper.py here 
    #wrapper:
    #    join(DIR_WRAPPER, "bwa/wrapper.py")
    shell:
         "bwa mem {params.extra} -t {threads} {params.index} {input} | samtools view -Sb - > {output} 2> {log}"

## 2. sorting
rule samtools_sort:
    input:
        join(DIR_RES, "01_aligned/{sample}.bam")
    output:
        join(DIR_RES, "02_sorted/{sample}.sorted.bam")
    log:
        join(DIR_LOGS, "samtools_sort/{sample}.sort.log")
    benchmark:
        join(DIR_BENCHMARKS, "samtools_sort/{sample}.txt")
    threads: 4
    conda:
        join(DIR_ENVS, "bwa-samtools.yaml")
    params:
        extra=config["extra"]["samtools_sort"]
    shell:
        "samtools sort {params.extra} -@ {threads} -o {output[0]} -T %s/{wildcards.sample} {input[0]}" %(join(DIR_RES, "02_sorted"))
        
## 3. INDEXING
rule samtools_index:
    input:
        join(DIR_RES, "02_sorted/{sample}.sorted.bam")
    output:
        join(DIR_RES, "02_sorted/{sample}.sorted.bam.bai")
    log:
        join(DIR_LOGS, "samtools_index/{sample}.index.log")
    benchmark:
        join(DIR_BENCHMARKS, "samtools_index/{sample}.txt")
    conda:
        join(DIR_ENVS, "bwa-samtools.yaml")
    params:
        extra=config["extra"]["samtools_index"]
    shell:
        "samtools index {params.extra} {input[0]} {output[0]}"

    
## 4. VAR CALL
include: join(DIR_RULES, "freebayes.smk")
    

rule clean:
    shell:
        "rm -rf {DIR_BASE}/*"
