## WWORKFLOW PROJECT: {{cookiecutter.package_name}}
## INIT DATE: {{cookiecutter.date}}
import glob, os, os.path, datetime, sys, csv
from os.path import join
## For data download
from snakemake.remote.FTP import RemoteProvider as FTPRemoteProvider
FTP = FTPRemoteProvider()

## =============================================================================
## SETUP
## =============================================================================

## define global Singularity image for reproducibility
## USE: "--use-singularity --use-conda" to run all jobs in container
singularity: "docker://continuumio/miniconda3:4.5.4"


## =======================================================================
## LOAD VARIABLES FROM CONFIGFILE
## different config-file can be submitted on command-line via --configfile
configfile: "config.yml"

BASEDIR       = os.path.abspath(config["base"])
LOGDIR        = os.path.abspath(config["logdir"])
BENCHMARKDIR  = os.path.abspath(config["benchmarkdir"])
WRAPPERDIR    = os.path.abspath(config["wrapperdir"])
SCRIPTDIR     = os.path.abspath(config["scriptdir"])
ENVDIR        = os.path.abspath(config["envdir"])

# DATA
GENOMEDIR     = os.path.abspath(config["genome"]["dir"])
GENOMEGZ      = join(GENOMEDIR, config["genome"]["genome"])
GENOME        = GENOMEGZ.replace(".gz", "")
#GENOMEFTP     = config["genome"]["genomeftp"]
#ANNOTATIONFTP = config["genome"]["gtfftp"]
#ANNOTATIONGZ  = join(GENOMEDIR, config["genome"]["gtf"])
#ANNOTATION    = join(GENOMEDIR, config["genome"]["gtf"].replace(".gz", ""))
#ANNOTATIONBED = join(GENOMEDIR, config["genome"]["gtf"].replace(".gtf.gz", ".bed"))

# SAMPLES
SAMPLEDIR     = os.path.abspath(config["samples"]["dir"])
SAMPLESHEET   = os.path.abspath(config["samples"]["samplesheet"])
R1            = config["samples"]["r1"]
R2            = config["samples"]["r2"]

# OUTPUTS
RES           = os.path.abspath(config["results"])
MAPPINGDIR    = join(RES, config["outputs"]["mapping"])
SORTDIR       = join(RES, config["outputs"]["sort"])
VARDIR        = join(RES, config["outputs"]["var"])

##------------------------------------------
## SAMPLES
if SAMPLESHEET != "None":
    ## reading samplename from samplesheet
    sys.stderr.write('Reading samples from samplesheet: "{}"\n'.format(SAMPLESHEET))
    SAMPLES = []
    reader = csv.reader(open(SAMPLESHEET), delimiter="\t")
    for a in reader:
        SAMPLES.append(a[0])

    # test if sample in dir
    for fname in expand(join(SAMPLEDIR, R1), sample=SAMPLES):
        if not os.path.isfile(fname):
            sys.stderr.write("File '{}' from samplesheet can not be found. Make sure the file exists. Exit\n".format(fname))
            sys.exit()
else:
    ## INPUT SAMPLE FILES FROM DIRECTORY
    sys.stderr.write('Reading samples directory: "{}"\n'.format(SAMPLEDIR))
    SAMPLES, = glob_wildcards(join(SAMPLEDIR, R1))

    
NUM_SAMPLES = len(SAMPLES)
sys.stderr.write('{} samples to process\n'.format(NUM_SAMPLES))

## TARGETS
TARGETS = expand(join(VARDIR, "{sample}.vcf"), sample=SAMPLES)

## Pseudo-rule to stae the final targets, so that the whole
## workflow is run.
rule all:
     input:
         expand(join(VARDIR, "{sample}.vcf"), sample=SAMPLES)
        

## 1. MAPPING
rule bwa_mem:
    input:
        join(SAMPLEDIR, "{sample}.fastq")
    output:
        temp(join(MAPPINGDIR, "{sample}.bam"))
    log:
        join(LOGDIR, "bwa_mem/{sample}.log")
    benchmark:
        join(BENCHMARKDIR, "bwa_mem/{sample}.txt")
    params:
        index=GENOME,
        extra=r"-R '@RG\tID:{sample}\tSM:{sample}'",
        sort="samtools",         ## Can be 'none', 'samtools' or 'picard'.
        sort_order="queryname",  ## Can be 'queryname' or 'coordinate'.
        sort_extra=""            ## Extra args for samtools/picard.
    threads: 8
    conda:
        join(ENVDIR, "bwa-samtools.yaml")
    ## When using a wrapper, specify dir with wrapper.py here 
    #wrapper:
    #    "file://%s/bwa" $(WRAPPERDIR)
    ## When not using wrapper give commmand explicitly
    shell:
         "bwa mem -t {threads} {params.extra} {params.index} {input} | samtools view -Sb - > {output} 2> {log}"


## 2. sorting
rule samtools_sort:
    input:
        join(MAPPINGDIR, "{sample}.bam")
    output:
        join(SORTDIR, "{sample}.sorted.bam")
    log:
        join(LOGDIR, "samtools_sort/{sample}.sort.log")
    benchmark:
        join(BENCHMARKDIR, "samtools_sort/{sample}.txt")
    params:
        "-m 4G"
    threads: 8
    conda:
        join(ENVDIR, "bwa-samtools.yaml")
    #wrapper:
    #    "file://wrapper/samtools_sort"
    shell:
        "samtools sort {params} -@ {threads} -o {output[0]} -T %s/{wildcards.sample} {input[0]}" %(SORTDIR)
        


## 3. INDEXING
rule samtools_index:
    input:
        join(SORTDIR, "{sample}.sorted.bam")
    output:
        join(SORTDIR, "{sample}.sorted.bam.bai")
    log:
        join(LOGDIR, "samtools_index/{sample}.index.log")
    benchmark:
        join(BENCHMARKDIR, "samtools_index/{sample}.txt")
    params:
        ""
    conda:
        join(ENVDIR, "bwa-samtools.yaml")
    #wrapper:
    #    "file://wrapper/samtools_index"
    shell:
        "samtools index {params} {input[0]} {output[0]}"


## 4. VAR CALL
rule freebayes:
    input:
        samples = join(SORTDIR, "{sample}.sorted.bam"),
        bai     = join(SORTDIR, "{sample}.sorted.bam.bai")
    output:
        join(VARDIR, "{sample}.vcf")
    log:
        join(LOGDIR, "freebayes/{sample}.log")
    benchmark:
        join(BENCHMARKDIR, "freebayes/{sample}.txt")
    params:
        index=GENOME,
        extra=""  ## optional parameters
    conda:
        join(ENVDIR, "freebayes.yaml")
)    #wrapper:
    #    "file://wrapper/freebayes/wrapper.py"
    shell:
        "freebayes {params.extra} -f {params.index} {input.samples} > {output} 2> {log}"
        
rule clean:
     shell:
        "rm -rf {BASEDIR}/*"
        
        
